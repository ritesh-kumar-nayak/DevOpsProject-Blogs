---
title: "Containerization with Docker-1"
datePublished: Sun Jan 15 2023 14:57:21 GMT+0000 (Coordinated Universal Time)
cuid: clcxi4372000508lb9z467m20
slug: containerization-with-docker-1
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1673794163178/07a6644f-71d9-44a8-bf4c-e16dedb739ec.png
tags: docker, devops, devops-articles, containerization-vs-virtualization, devops-journey

---

## What is Docker?

Docker is a platform that allows developers to easily deploy, run, and manage applications in containers. Containers are lightweight, portable, and self-sufficient, meaning they can run on any system with Docker installed, regardless of the underlying infrastructure. This makes it easy to move applications between different environments, such as from development to production, and to scale them up or down as needed.

## Docker Architecture

Docker's architecture consists of several components, including the Docker daemon, the Docker client, and the Docker registry.

The Docker daemon is responsible for managing the lifecycle of containers, including starting, stopping, and monitoring them. It communicates with the Docker client, which is used to issue commands to the daemon. The Docker client and daemon can run on the same host, or the daemon can run remotely, with the client communicating with it over the network.

The Docker registry is a service that stores and distributes Docker images, which are snapshots of a container's filesystem and configuration. The most common registry is Docker Hub, which is a public registry that anyone can use. However, organizations can also run their private registries, either on-premises or in the cloud.

Docker also includes several other components, such as the Docker engine, which is the underlying technology that powers the platform, and the Docker Compose and Docker Swarm tools, which are used for the orchestration and scaling of containerized applications.

## Stages of Containerization

**Create DockerFile ---b-u-i-l-d--&gt; Image ---r-u-n----&gt; Container**

1. The first stage is the base image. This is the starting point for the image and typically includes the operating system and any necessary dependencies.
    
2. The next stage is the build stage. During this stage, files are copied into the image, packages are installed, and any necessary configurations are made.
    
3. The next stage is the runtime stage. This is the final stage of the image and includes the command that will be run when a container is started from the image.
    
4. Lastly, the last stage ( optional) is the Multi-stage build, a feature that allows you to use multiple `FROM` statements in your Dockerfile. This can be useful for separating build-time dependencies from runtime dependencies.
    

## What is Docker Hub?

Docker Hub is the default registry when working with the Docker command-line interface, so developers do not need to specify the registry when pulling or pushing images.

Docker Hub is a public registry service provided by Docker Inc. that allows developers to store and distribute their Docker images. It is similar to other registry services such as the Python Package Index (PyPI) for Python or the npm registry for Node.js. It allows developers to easily share and collaborate on their images with others.

# Docker Commands Illustration with hands-on

`docker ps`: This command is used to list all running containers. The output will show the container ID, image, status, and other information.

**Error while running docker PS for the first time**

**Error Resolution**

`docker pull`: This command is used to download an image from a registry. For example, `docker pull ubuntu` will download the latest version of the Ubuntu image from the Docker Hub registry.

`docker run -it --name nameByYou containerName:tagName` **:**

**Example:** `docker run -it --name MySQL_DB -e MYSQL_ROOT_PASSWORD=test@123 mysql:latest`

`-it` : Interactive Terminal

\--name nameOFthecontainer: used to name the container

`-e` : It denotes the environment variable and we are passing the **root password** of MySQL DB as it is mandatory for configuration

containerName:tagName : `mysql:latest` it refers to identifying the container name and version

`docker ps -a` **:** It shows all the active and inactive containers whereas docker **pa** shows only active containers. Below is an example of an inactive container with all its details such as `CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES` .

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673769387996/70ad4cac-b0bf-4a9d-b09d-f27ff5c09b27.png align="left")

`docker rm containerID` **:** It is used to remove an inactive or active container which is specified by its container id. Below is an illustration of before and after applying the docker rm command.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673769642004/7e0c8d8c-ce56-483c-a503-7052f785a375.png align="center")

After a successful run of the docker image, it looks as below. It shows the logs in the interactive terminal of **docker** as we specified the option **\-it** (Interactive Terminal).

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673770183071/9188c685-fbe9-4491-a1c4-b8d3ff8f5b9e.png align="center")

Now the details of the active container look like below:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673770229559/ca256113-c35c-43af-9818-27ff75425522.png align="center")

`docker exec`: This command allows to running of a command inside a running container. For example, `docker exec -it <container_id> /bin/bash` will open a bash shell inside the running container specified by container\_id.

`$ docker exec -it 384855b38b9b bash` : exec command with option -it helps us to access the bash terminal of the specified container itself. It enables us to run any command inside the container if required. Once this command is hit, it is talking to the bash of docker.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673770851696/216f0f03-16e6-4b4b-b500-c0d14d4cf240.png align="center")

The above image illustrates that we entered MySQL using `$ docker exec -it 384855b38b9b bash` .

`mysql -u root -p` is the command that allows us to get inside mysql using the root password which we set earlier as **test@123**

And now we can interact with mysql as below, here we logged in, checked the databases and came out of the **SQL CLI** as well as the **bash of docker**

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673771433144/44716b71-8167-47dc-a0ed-1448ef925cfb.png align="left")

`docker stop`: This command is used to stop a running container. For example, `docker stop <container_id>` will stop the container with the specified ID.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673793875430/6e19e846-9d67-4c2a-a1e0-4a71518b922b.png align="left")

## How to access a Running container in Other systems?

To do so we have to give access to the hosted port to the other systems by mapping the port as below:

`docker run -d -p 3306:3306 mysql:latest`

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673774554021/92526d09-373f-4c5d-bd7d-0d257ec795b3.png align="left")

Here **\-d** means in daemon mode

**\-p** refers to the port number at which it is hosted

# Docker File

### What is Docker File?

A Dockerfile is a script that contains instructions to build a Docker image. Each instruction in the Dockerfile creates a new layer in the image. When you build an image, Docker reads the instructions in the Dockerfile and creates an image that includes the specified base image and the additional changes specified in the Dockerfile.

### How to create a docker file?

To create a Dockerfile, you can use a text editor to create a new file with the filename "Dockerfile" (no file extension). The first line of the file should be the `FROM` command, which specifies the base image that the new image will be built on top of. Other common commands include `RUN` to run commands in the image, `COPY` to copy files from the host into the image, `EXPOSE` to open ports in the image, and `CMD` to specify the command that will be run when a container is started from the image. Once you have created the Dockerfile, you can use the `docker build` command to build an image from the Dockerfile.

**Example:**

**#Use the official nginx image as the base image**

`FROM nginx:latest`

**\# Copy the web server files from the host into the image**

`COPY . /usr/share/nginx/html`

**\# Open port 80 in the image**

`EXPOSE 80`

**Start the nginx web server when a container is run from this image**

`CMD ["nginx", "-g", "daemon off;"]`

the Dockerfile starts with the `FROM` instruction, which specifies that the image is based on the latest version of the official nginx image. The `COPY` instruction copies the web server files from the host into the image, and the `EXPOSE` instruction opens port 80. The `CMD` instruction specifies that the nginx web server should be started when a container is run from this image.

Once you have created the Dockerfile, you can use the `docker build` command to build the image, like this:

`docker build -t my-nginx-image .`

The `-t` flag specifies a name for the image and the `.` specifies the location of the Dockerfile. After the build completed, you can run the container with the built image using the

`docker run -p 8080:80 my-nginx-image`

In this command, the `-p` flag maps port 80 in the container to port 8080 on the host, so you can access the web server by visiting [**http://localhost:8080**](http://localhost:8080) in a web browser.

# Projects

## 1- Running Jenkins using Docker

`docker pull jenkins/jenkins`

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673775043305/ef56491f-0ef7-4bd9-afbe-2fa324ae5aa6.png align="center")

**Running Jenkins:**

`$ docker run -d --name JenkinsServerbyDocker jenkins/jenkins:latest` : -d means in detached mode. In the case of MySQL, we used -it (interactive terminal) so that it took us inside the docker terminal. However, here we are running in detached mode.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673776040277/f5b4278a-14f2-45d3-a73d-8002d98abfcd.png align="center")

**Port Mapping for global access**

`$ docker run -d --name JenkinsServerbyDocker -p 8080:8080 jenkins/jenkins:latest` .

After mapping the port number then allow port number **8080** in the security group inbound rule because **Jenkins** always runs on the system's port number 8080.

Which will look like below:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673776649707/2ebe8945-45a0-4809-9bd5-35c5b3b8e226.png align="left")

After exposing the port number copy your instances' public ip and add port 8080 on your browser as below.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673776746290/31c0f4f7-dc4a-4446-b026-d9202bdad0b4.png align="left")

Now you are successfully opening the Jenkins server on another system that is running in **Docker Engine** in an EC2 instance somewhere.

## 2-Running NGINX in docker and exposing outside

Get the docker image of NGINX from by `docker pull nginx`

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673779715573/1028e2ad-fa29-441f-a0f4-4ec02372a013.png align="center")

Run the image and map the port to **80:80** as below before that make sure that the inbound rule for port 80 is accessible in your host system.

`$ docker run --name mynginx1 -p 80:80 -d nginx`

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673779737279/c9db2567-1936-4eea-a8ec-a06c70afc3e1.png align="center")

Make sure it's up and running by `docker ps`

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673779815069/11a534fa-f875-4c6c-8432-c3247985a5f5.png align="left")

Then you can view the Nginx page in any system's browser as below:

Provided: [`http://`](http://54.163.56.77/)`hostIP:80`

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673779893642/78b56317-ac37-47a3-a6e6-f0fe2bc66aed.png align="center")

## 3-Dockerizing Django based app from opensource

**Step-1**

Bring your project from the respective repository to your local system(EC2 Instance). Here we have used

`git clone` [`https://github.com/LondheShubham153/react_django_demo_app.git`](https://github.com/LondheShubham153/react_django_demo_app.git) `.`

**Step-2(Creating docker file)**

Once the project is clonned, get inside the project directory and write the docker file as below for this particular project:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673791897252/0f0a1825-4e27-4169-8b04-a3b022a46eda.png align="left")

As we have discussed above in How to create Docker file segment

`FROM python:3.9` denotes the base on the top of which this project is built. It will automatically download all the dependencies required such as python3.9, Django, pip for running pip commands etc...

`COPY . .` when this line executes, it will copy all the project files into the docker container, here **copy . .** means the source is **.(this directory)** and destination is **.(this directory)** as well because the project files, as well as Dockerfile, are present in the same directory in this case.

`RUN pip install -r requirements.txt` when this line executes it will install all the python libraries written inside the **requirements.txt** file which will support the project.

The requirements.txt file contains the below libraries that will be installed on executing the above RUN command:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673790219841/c055abe4-f626-4cfc-b990-e5ac29682331.png align="left")

`EXPOSE 8000` : This will enable the app to go outside of container through the port 8000 and will be available for outside

**Step-3(Building the docker file)**

`docker build . -t django-app` : this command will build the image from the above-written Dockerfile

As the docker file has been build, let's check the image by:

`$docker images` : this will list all the images created until this point in time.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673790769464/1506b53b-5f6e-42e8-8db4-233dd625abc7.png align="left")

**Django-app** named image has been built.

**Step-4(Converting the Image to Container)**

`$ docker run -d -p 8000:8000 --name DjangoAppDockerized django-app:latest` : It will run the docker image and create a container out of it.

`-p 8080:8080` will expose the 8080 port for public access.

`$ docker ps` : To check if the container is up

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673792443907/c0fe5497-6f8d-4409-91ac-9b19c6ba694b.png align="left")

**Step-4(Making sure the host system's port is allowed)**

Make sure the inbound rule of EC2 instance(Host Server) port **8000** is allowed as below as the Django app runs on port number 8000.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673791466571/90125a83-5988-4c48-8811-d974f14cdec3.png align="center")

**Step-5(Viewing the app running on browser)**

Finally, hit [http://hostPublicIP:8000/](http://174.129.183.30:8000/) on your web browser and see the app running.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673792570685/4af05e7b-89c9-4fc5-914f-dc082421f66c.png align="left")